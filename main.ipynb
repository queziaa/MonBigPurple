{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-01T07:40:49.065336Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from MonBigTool import IS_levenshtein_distance_and_operations\n",
    "from MonBigTool import MonBigTool,MASKmodel\n",
    "from collections import Counter\n",
    "\n",
    "mASKmodel = MASKmodel()\n",
    "monBigTool = MonBigTool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = monBigTool.getMASK()\n",
    "WINDOW = 3\n",
    "\n",
    "LOSS_PScore = 0\n",
    "LOSS_PError = 0\n",
    "LOSS_PMiss = 0\n",
    "LOSS_PTrue = 0\n",
    "LOSS_PTrue_errFix = 0\n",
    "LOSS_PTrue_succFix = 0\n",
    "\n",
    "\n",
    "\n",
    "COUNT = 0\n",
    "LENMASK = len(MASK)\n",
    "for ii in tqdm(range(LENMASK)):\n",
    "    ii = random.choice(range(LENMASK))\n",
    "    i = MASK[ii]\n",
    "    COUNT += 1\n",
    "    # i = random.choice()\n",
    "    inode,tsen,fsen,sen,freq,pairs = monBigTool.Decode(i)\n",
    "\n",
    "    # ########################################\n",
    "    # # 得到词对 信息  ########################\n",
    "    # for g in pairs:\n",
    "    #     if not g[0].isalpha():\n",
    "    #         continue\n",
    "\n",
    "\n",
    "    #     # te = monBigTool.letterSim(g[0],g[1])\n",
    "    #     # if te < 0.8:\n",
    "    #         # print(g[0],g[1],te)\n",
    "    # ########################################\n",
    "\n",
    "\n",
    "    temp = mASKmodel.tomask(fsen,WINDOW,False)\n",
    "    SecondaryTreatment = []\n",
    "    for i in range(len(fsen)):\n",
    "        if not fsen[i].isalpha():\n",
    "            continue\n",
    "        if fsen[i] in temp[i] and len(fsen[i]) > 2:\n",
    "            continue\n",
    "        SecondaryTreatment.append(i)\n",
    "\n",
    "    print('假----',' '.join(fsen),'----')\n",
    "    print('真----',' '.join(tsen),'----')\n",
    "    print('MASK----',' '.join(sen),'----')\n",
    "    print('怀疑----',SecondaryTreatment)\n",
    "\n",
    "\n",
    "    for i in SecondaryTreatment:\n",
    "        TTEMP = []\n",
    "        Alternate = []\n",
    "        temp = monBigTool.FuzzySearch(fsen[i])\n",
    "\n",
    "        print(fsen[i],':  :',temp)\n",
    "        for new in temp:\n",
    "            fsen[i] = new\n",
    "            AAA = mASKmodel.AttFix(fsen,WINDOW,i)\n",
    "            TTEMP += AAA              \n",
    "\n",
    "        if len(TTEMP) == 0:\n",
    "            continue\n",
    "\n",
    "        counter = Counter(TTEMP)\n",
    "        TTEMP, count = counter.most_common(1)[0]\n",
    "\n",
    "        print('结果:',TTEMP)\n",
    "        if fsen[i] in TTEMP:\n",
    "            continue\n",
    "    \n",
    "        if i not in inode:\n",
    "            LOSS_PError += 1\n",
    "            print('*ERR'*20)\n",
    "            print('----',' '.join(fsen),'----')\n",
    "            print('----',' '.join(tsen),'----')\n",
    "            print('----',' '.join(sen),'----')\n",
    "            print(fsen[i],temp[i])\n",
    "            print(fsen[i],TTEMP)\n",
    "        elif i in inode:\n",
    "            LOSS_PTrue += 1\n",
    "            inode.remove(i)\n",
    "            if tsen[i] == TTEMP:\n",
    "                LOSS_PTrue_succFix += 1\n",
    "            else:\n",
    "                LOSS_PTrue_errFix += 1\n",
    "    \n",
    "    LOSS_PMiss += len(inode)\n",
    "    for i in inode:\n",
    "        print('@MISS'*20)\n",
    "        print('----',' '.join(fsen),'----')\n",
    "        print('----',' '.join(tsen),'----')\n",
    "        print('----',' '.join(sen),'----')\n",
    "        print(fsen[i],temp[i])\n",
    "        print(fsen[i],TTEMP)\n",
    "\n",
    "    # if COUNT % 50 == 0:\n",
    "    print('-----------------')\n",
    "    print('PError:',LOSS_PError)\n",
    "    print('PMiss:',LOSS_PMiss)\n",
    "    print('PTrue:',LOSS_PTrue)\n",
    "    print('PTrue_succFix:',LOSS_PTrue_succFix)\n",
    "    print('PTrue_errFix:',LOSS_PTrue_errFix)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------')\n",
    "print('PError:',LOSS_PError)\n",
    "print('PMiss:',LOSS_PMiss)\n",
    "print('PTrue:',LOSS_PTrue)\n",
    "print('PTrue_succFix:',LOSS_PTrue_succFix)\n",
    "print('PTrue_errFix:',LOSS_PTrue_errFix)\n",
    "\n",
    "# PError: 9\n",
    "# PMiss: 104\n",
    "# PTrue: 86\n",
    "# PTrue_succFix: 78\n",
    "# PTrue_errFix: 8\n",
    "\n",
    "# PError: 5\n",
    "# PMiss: 107\n",
    "# PTrue: 82\n",
    "# PTrue_succFix: 78\n",
    "# PTrue_errFix: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(MASK)):\n",
    "    i = MASK[ii]\n",
    "    inode,tsen,fsen,sen,freq,pairs = monBigTool.Decode(i)\n",
    "    if fsen[0] == 'энэ':\n",
    "        print(ii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('tugstugi/bert-large-mongolian-uncased', use_fast=False)\n",
    "model = AutoModelForMaskedLM.from_pretrained('tugstugi/bert-large-mongolian-uncased')\n",
    "\n",
    "# 词嵌入\n",
    "input_text = \"тан\"\n",
    "              \n",
    "encoded_input = tokenizer.encode(input_text, return_tensors='pt')\n",
    "outputs = model(encoded_input)\n",
    "last_hidden_states = outputs[0]\n",
    "# 解码 last_hidden_states\n",
    "\n",
    "# 选择每个位置最可能的 token ID\n",
    "predicted_ids = torch.argmax(last_hidden_states[0], dim=1)\n",
    "\n",
    "\n",
    "# 解码 predicted_ids\n",
    "for i in predicted_ids:\n",
    "    print(tokenizer.decode(i))\n",
    "\n",
    "print(tokenizer.decode(predicted_ids.tolist()))\n",
    "last_hidden_states.shape\n",
    "stelist = ['aa1','aa','dsada1sd','']\n",
    "ssd=[1,2,3,4]\n",
    "[ssd[i] for i in range(len(stelist)) if stelist[i].isalpha() or stelist[i]=='']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "TTEMP = [1,2,3,3,12,2,4,45,3,534,5,43]\n",
    "\n",
    "# 使用 Counter 计算每个元素的出现次数\n",
    "counter = Counter(TTEMP)\n",
    "\n",
    "# 找出出现次数最多的元素\n",
    "most_common_element, count = counter.most_common(1)[0]\n",
    "\n",
    "print(most_common_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weibodatacleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
