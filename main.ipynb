{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-01T07:40:49.065336Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from MonBigTool import IS_levenshtein_distance_and_operations\n",
    "from MonBigTool import MonBigTool,MASKmodel\n",
    "from collections import Counter\n",
    "\n",
    "mASKmodel = MASKmodel()\n",
    "monBigTool = MonBigTool()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = monBigTool.getMASK()\n",
    "WINDOW = 3\n",
    "\n",
    "LOSS_PScore = 0\n",
    "LOSS_PError = 0\n",
    "LOSS_PMiss = 0\n",
    "LOSS_PTrue = 0\n",
    "LOSS_PTrue_errFix = 0\n",
    "LOSS_PTrue_succFix = 0\n",
    "\n",
    "\n",
    "\n",
    "COUNT = 0\n",
    "LENMASK = len(MASK)\n",
    "for ii in tqdm(range(LENMASK)):\n",
    "    ii = random.choice(range(LENMASK))\n",
    "    i = MASK[ii]\n",
    "    COUNT += 1\n",
    "    # i = random.choice()\n",
    "    inode,tsen,fsen,sen,freq,pairs = monBigTool.Decode(i)\n",
    "\n",
    "    # ########################################\n",
    "    # # 得到词对 信息  ########################\n",
    "    # for g in pairs:\n",
    "    #     if not g[0].isalpha():\n",
    "    #         continue\n",
    "\n",
    "\n",
    "    #     # te = monBigTool.letterSim(g[0],g[1])\n",
    "    #     # if te < 0.8:\n",
    "    #         # print(g[0],g[1],te)\n",
    "    # ########################################\n",
    "\n",
    "\n",
    "    temp = mASKmodel.tomask(fsen,WINDOW,False)\n",
    "    SecondaryTreatment = []\n",
    "    for i in range(len(fsen)):\n",
    "        if not fsen[i].isalpha():\n",
    "            continue\n",
    "        if fsen[i] in temp[i] and len(fsen[i]) > 2:\n",
    "            continue\n",
    "        if monBigTool.mysterious(fsen[i]):\n",
    "            continue\n",
    "        SecondaryTreatment.append(i)\n",
    "\n",
    "    print('假----',' '.join(fsen),'----')\n",
    "    print('真----',' '.join(tsen),'----')\n",
    "    print('MASK----',' '.join(sen),'----')\n",
    "    print('怀疑----',SecondaryTreatment,'----',inode)\n",
    "\n",
    "\n",
    "    for i in SecondaryTreatment:\n",
    "        Alternate = []\n",
    "        candidate = monBigTool.FuzzySearch(fsen[i])\n",
    "        Target = fsen[i]\n",
    "\n",
    "        TTEMP = mASKmodel.hybridPrediction(fsen,i,5,candidate)\n",
    "        # TTEMP = candidate\n",
    "        print('目标',Target,':  候选',candidate)\n",
    "        print('结果:',TTEMP)\n",
    "\n",
    "\n",
    "        if len(TTEMP) == 0:\n",
    "            continue\n",
    "\n",
    "        if fsen[i] == TTEMP[0]:\n",
    "            continue\n",
    "    \n",
    "        if i not in inode:\n",
    "            LOSS_PError += 1\n",
    "            print('*ERR'*20)\n",
    "            print(Target,TTEMP)\n",
    "        elif i in inode:\n",
    "            LOSS_PTrue += 1\n",
    "            inode.remove(i)\n",
    "            if tsen[i] == TTEMP[0]:\n",
    "                print('*SUCFix'*20)\n",
    "                LOSS_PTrue_succFix += 1\n",
    "            else:\n",
    "                print('*ERRFix'*20)\n",
    "                LOSS_PTrue_errFix += 1\n",
    "            print(Target,TTEMP)\n",
    "    \n",
    "    LOSS_PMiss += len(inode)\n",
    "    for i in inode:\n",
    "        print('@MISS'*20)\n",
    "        print('----',' '.join(fsen),'----')\n",
    "        print('----',' '.join(tsen),'----')\n",
    "        print('----',' '.join(sen),'----')\n",
    "        print(fsen[i])\n",
    "        print(fsen[i])\n",
    "\n",
    "    # if COUNT % 50 == 0:\n",
    "    print('-----------------')\n",
    "    print('PError:',LOSS_PError)\n",
    "    print('PMiss:',LOSS_PMiss)\n",
    "    print('PTrue:',LOSS_PTrue)\n",
    "    print('PTrue_succFix:',LOSS_PTrue_succFix)\n",
    "    print('PTrue_errFix:',LOSS_PTrue_errFix)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-----------------')\n",
    "print('PError:',LOSS_PError)\n",
    "print('PMiss:',LOSS_PMiss)\n",
    "print('PTrue:',LOSS_PTrue)\n",
    "print('PTrue_succFix:',LOSS_PTrue_succFix)\n",
    "print('PTrue_errFix:',LOSS_PTrue_errFix)\n",
    "\n",
    "# PError: 9\n",
    "# PMiss: 104\n",
    "# PTrue: 86\n",
    "# PTrue_succFix: 78\n",
    "# PTrue_errFix: 8\n",
    "\n",
    "# PError: 5\n",
    "# PMiss: 107\n",
    "# PTrue: 82\n",
    "# PTrue_succFix: 78\n",
    "# PTrue_errFix: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(len(MASK)):\n",
    "    i = MASK[ii]\n",
    "    inode,tsen,fsen,sen,freq,pairs = monBigTool.Decode(i)\n",
    "    if fsen[0] == 'энэ':\n",
    "        print(ii)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('tugstugi/bert-large-mongolian-uncased', use_fast=False)\n",
    "model = AutoModelForMaskedLM.from_pretrained('tugstugi/bert-large-mongolian-uncased')\n",
    "\n",
    "# 词嵌入\n",
    "input_text = \"хэрэв зориудаар алсан оол тэр хэмжээний малаар торгууль төлж цайруулмуй\"\n",
    "              \n",
    "encoded_input = tokenizer.encode(input_text, return_tensors='pt')\n",
    "outputs = model(encoded_input)\n",
    "last_hidden_states = outputs[0]\n",
    "# 解码 last_hidden_states\n",
    "\n",
    "# 选择每个位置最可能的 token ID\n",
    "predicted_ids = torch.argmax(last_hidden_states[0], dim=1)\n",
    "\n",
    "print(input_text)\n",
    "print(tokenizer.decode(predicted_ids.tolist()))\n",
    "\n",
    "\n",
    "# 真---- хэрэв зориудаар алсан бол тэр хэмжээний малаар торгууль төлж цайруулмуй . ----\n",
    "# MASK---- хэрэв зориудаар алсан [MASK] тэр хэмжээний малаар торгууль төлж [MASK] . ----\n",
    "# 怀疑---- [3, 6, 9] ---- [3, 9]\n",
    "# обл :  : ['сбл', 'ойл', 'обя', 'обг', 'убл', 'ол', 'оол', 'орл', 'оёл', 'об', 'бл', 'оби', 'оба', 'онл', 'нобл', 'обь', 'обх', 'дбл', 'ббл', 'обс', 'олл', 'оул', 'обт', 'обл', 'обе', 'эбл', 'обо', 'облж', 'шбл', 'обол', 'обу', 'осл', 'гобл', 'оил', 'общ', 'охл', 'хобл', 'обла', 'собл', 'обб', 'оел', 'объ', 'робл', 'добл', 'отл', 'нбл', 'лбл', 'обш', 'мбл']\n",
    "# 结果: ['мбл', 'нбл', 'мол', 'бол', 'нол']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_states[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weibodatacleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
