{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/Dorjzodovsuren/mongolian-gpt2/tree/main\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Dakie/mongolian-xlm-roberta-base\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Dakie/mongolian-xlm-roberta-base\")\n",
    "\n",
    "# prepare input\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# forward pass\n",
    "output = model(**encoded_input)\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bayartsogt/mongolian-gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"bayartsogt/mongolian-gpt2\")\n",
    "# 准备输入文本，这是模型生成续写的起点\n",
    "prompt_text = \"Өглөөний нар мандаж,\"  # 假设这意味着“早晨的太阳升起，”\n",
    "\n",
    "# 将文本编码为模型可以理解的格式\n",
    "input_ids = tokenizer.encode(prompt_text, return_tensors='pt')\n",
    "\n",
    "# 使用模型生成文本\n",
    "# num_return_sequences=1 表示生成一个续写\n",
    "# max_length 指定生成文本的最大长度，包括输入文本的长度\n",
    "output = model.generate(input_ids, max_length=50, num_return_sequences=1)\n",
    "\n",
    "# 解码生成的文本\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.C1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1)\n",
    "        self.S2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.C3 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        self.S4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.C5 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
    "        self.F6 = nn.Linear(in_features=120, out_features=84)\n",
    "        self.OUTPUT = nn.Linear(in_features=84, out_features=10)\n",
    " \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print('input:', x.size())\n",
    "        x = self.C1(x)\n",
    "        # print('C1:', x.size())\n",
    "        x = self.S2(torch.relu(x))\n",
    "        # print('S2:', x.size())\n",
    "        x = self.C3(x)\n",
    "        # print('C3:', x.size())\n",
    "        x = self.S4(torch.relu(x))\n",
    "        # print('S4:', x.size())\n",
    "        x = torch.relu(self.C5(x))\n",
    "        # print('C5:', x.size())\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # print('view:', x.size())\n",
    "        x = torch.relu(self.F6(x))\n",
    "        # print('F6:', x.size())\n",
    "        x = self.OUTPUT(x)\n",
    "        # print('OUTPUT:', x.size())\n",
    "        return x\n",
    "net = LeNet5()  # 创建LeNet5模型实例\n",
    "criterion = nn.CrossEntropyLoss()  # 定义损失函数为交叉熵损失\n",
    "optimizer = optim.Adam(net.parameters(), lr=2e-3)  # 定义优化器为Adam，学习率为0.002\n",
    "\n",
    "\n",
    "def train():\n",
    "    net.train()  # 将模型设置为训练模式\n",
    "    for i, (images, labels) in enumerate(data_train_loader):  # 遍历训练数据\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "        output = net(images)  # 前向传播\n",
    "        loss = criterion(output, labels)  # 计算损失\n",
    "        # 每10个批次打印一次损失\n",
    "        if i % 10 == 0:\n",
    "            print('Train - , Batch: %d, Loss: %f' % ( i, loss.detach().cpu().item()))\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新权重\n",
    "\n",
    "def test():\n",
    "    net.eval()  # 将模型设置为评估模式\n",
    "    total_correct = 0\n",
    "    avg_loss = 0.0\n",
    "    for i, (images, labels) in enumerate(data_test_loader):  # 遍历测试数据\n",
    "        output = net(images)  # 前向传播\n",
    "        avg_loss += criterion(output, labels).sum()  # 累计损失\n",
    "        pred = output.detach().max(1)[1]  # 获取预测结果\n",
    "        total_correct += pred.eq(labels.view_as(pred)).sum()  # 计算正确预测的数量\n",
    "\n",
    "    avg_loss /= len(data_test)  # 计算平均损失\n",
    "    print('Test Avg. Loss: %f, Accuracy: %f' % (avg_loss.detach().cpu().item(), float(total_correct) / len(data_test)))  # 打印平均损失和准确率\n",
    "train()  # 训练模型\n",
    "train()  # 训练模型\n",
    "test()  # 测试模型"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weibodatacleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
