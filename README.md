# 实验报告

## 简介
拼写检查（拼写纠错）任务是一项悠久的自然语言处理任务，旨在检测文本中的拼写错误并提供正确的拼写建议。拼写检查系统通常由两个主要组件组成：错误检测器和纠错器。当然如今也有些工作是将两个任务合并在一起，使用深度学习完成端到端的拼写纠错任务。

在机器学习之前就有通过规则的方式来进行拼写检查，例如使用词典。但是这种方法有一个缺点，就是无法处理未知词，以及当错误的词与另外一个正确的词相似时，可能会出现错误的纠正。尤其对于中文来说，使用拼写输入法导致拼写错误常表现为同音字、同形字、形近字等，这些错误很难通过规则来纠正。

之后随着机器学习算法的发展，几乎每一个当时火热的机器学习算法都被应用到了拼写检查任务中，例如贝叶斯方法、最大熵模型、条件随机场、神经网络等。其中神经网络在近年来取得了很大的进展，例如使用循环神经网络（RNN）、长短时记忆网络（LSTM）、卷积神经网络（CNN）等。这些方法通常会使用大量的数据进行训练，以提高模型的泛化能力。

下一个世代是以transformer为代表的预训练模型，这种模型在拼写检查任务中也取得了很好的效果。这种模型通常会使用大量的数据进行预训练，然后在特定任务上进行微调。这种方法的优点是可以很好的处理未知词，以及可以通过大量的数据进行训练，提高模型的泛化能力。如BERT、GPT、RoBERTa等。

这里为了开发的便捷性，我们在Hugging Face中寻找蒙古语的预训练模型，以此为基础开发拼写检查系统。

## 前期准备工作
这里对Huagging Face中的蒙古语预训练模型和多语言预训练模型进行了筛选，选择了一些适合拼写检查任务的模型。这些模型包括：
来自Baljinnyam[^1]的roberta
来自Blgn94[^2]的bert,roberta
来自bayartsogt[^3]的roberta,albert,bert
来自Dakie的[^4]的roberta,bert
来自tugstugi[^5]的bert
这些模型都是在蒙古语数据上进行了预训练的，在之后的各项任务中测试了这些模型的性能，最后选择了tugstugi的bert模型作为拼写检查系统的基础模型。


为了补充语料库，我们还使用了来自tugstugi整理的蒙古语新闻数据400M[^5]。

## 错误检测器
这里将任务分为两个部分，第一个部分是错误检测器，第二个部分是纠错器。
这里错误检测器一个简单的实现是使用分词器，将文本分词，对于拼写语言来说，分词器通常会将错误的词分成多个词，之后也可以通过词典来进一步检查.但是发现这会产生大量的假正例,几乎占据输出的一半,虽然之后的纠错器可以可以处理假正例,但是现任这会放大纠错器的错误率,显然当对于对于产生的Tf,会最后产生Tf*Cerrorrate个错误,所以这里我们选择了使用预训练模型来进行错误检测。
这里我们使用了tugstugi的bert模型，使用了400M的蒙古语新闻数据进行了微调，微调任务是token级的二分类任务，即对于每一个token，判断其是否是错误的token。这里使用了400M的数据进行了微调，错误样本有程序自动生成，产生两次内的拼写错误,包括删除、替换、插入、交换操作。对错误词后来所有位置标记,而非只标记错误token,这样可以更好的训练模型。要求模型寻找错误token位置是艰难地,因为很难区分一个词语中错误的位置,所以这里使用了一个简单的方法,即对于错误词的所有位置标记为错误,同时由此在最后预测时,提出两种策略,一种是单词中任意一个位置错误,即认为整个词是错误的,另一种是所有位置错误,即认为整个词是错误的。
这里在测试集上取得了很好的效果，F1值达到了0.9以上。并且由于这里假例子的数量较少，所以当纠错结果和原文相同,纠错器的设置了两个策略,则认为这里不存在错误跳过这里,另一种是认为这里存在错误,对于纠错器输出的多个结果,选择下一个

## 纠错器
这里是tugstugi的bert模型，由于其使用MASK任务训练，所以可以很好的处理纠错任务。这里使用了错误检测器的输出，MASK掉错误的token，然后使用bert模型预测这些token。但是这里产生两个问题,一个是准确率问题,和token还原问题.
这里采用使用波束搜索为生成多个路径并预测缺失标签。与贪婪搜索不同，贪婪搜索在每一步选择概率最高的候选者，波束搜索维护一组最有前途的候选序列，称为波束。具体来说，算法如下进行： 

1.模型为错误位置𝑖生成一组词包括原文,MASK标记,和从词典中根据编辑距离搜索的相似词,对所以词替换错误位置进入Bert

2.每次选择概率最高的前𝑘个候选者，其中𝑘是波束宽度。 

3.将选定的候选者附加到前面的部分序列（从位置1到𝑖−1的预测标签）上，并计算扩展序列的联合概率。 


这里借由"扰乱"错误位置多次预测,希望得到这个位置更平均的预测结果,经过实验这一策略显然能提高性能


波束搜索算法旨在最大化整个序列的概率。执行波束搜索后，我们将所有解码路径合并在一个扁平列表中，并按照它们的各自概率对标签进行排序以产生最终排名。具体来说，对于错误位置i，让P(𝑙𝑗|𝑙1, . . . 𝑙𝑗−1)表示在路径𝑙1, . . . 𝑙𝑗−1给定的情况下观察到标签𝑙𝑗的预测概率。我们计算标签𝑙𝑗的路径独立边际概率为 P(𝑙𝑗) = max 可能路径𝑙1,...,𝑙𝑗−1 Ö 𝑗 𝑖=1 P(𝑙𝑖 |𝑙1, . . . 𝑙𝑖−1) ! 换句话说，我们取标签在分类法中所有可能路径上出现的最大概率。 

 



[^1]: [Baljinnyam Dayan](https://huggingface.co/Baljinnyam)
[^2]: [Blgn94](https://huggingface.co/Blgn94)
[^3]: [bayartsogt](https://huggingface.co/bayartsogt)
[^4]: [Dakie](https://huggingface.co/Dakie)
[^5]: [tugstugi](https://huggingface.co/tugstugi)


## 


在拼写纠错任务中，WER（Word Error Rate）和CER（Character Error Rate）是两个常用的性能指标，用于评估模型的纠错效果。

WER（Word Error Rate）：

定义：WER 是衡量系统输出与参考文本之间差异的指标，计算公式为：

WER = (S + D + I) / N
其中，S 是替换错误（substitutions），D 是删除错误（deletions），I 是插入错误（insertions），N 是参考文本中的单词总数。
用途：WER 主要用于评估语音识别系统和文本纠错系统的性能，反映了系统在单词层面上的错误率。
CER（Character Error Rate）：

定义：CER 是衡量系统输出与参考文本之间差异的指标，计算公式为：

CER = (S + D + I) / N
其中，S 是替换错误（substitutions），D 是删除错误（deletions），I 是插入错误（insertions），N 是参考文本中的字符总数。
用途：CER 主要用于评估文本纠错系统的性能，反映了系统在字符层面上的错误率。
这两个指标都用于量化模型的纠错能力，但侧重点不同：WER 关注单词层面的错误，而 CER 关注字符层面的错误。选择使用哪一个指标取决于具体应用场景和需求。


https://spellcheck.gov.mn/



https://github.com/shibing624/pycorrector/tree/master/examples/macbert