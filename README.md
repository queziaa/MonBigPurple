EEEEE {"wer": 0.18132890245444203, "cer": 0.039592995085484875}
7500 {"wer": 0.16214849464501796, "cer": 0.035668605788474216}
4000 {"wer": 0.16176922104426664, "cer": 0.03551512123774757}
1500 {"wer": 0.16641080749155665, "cer": 0.03631865800331647}
500  {"wer": 0.1677472954180137, "cer": 0.036634655607753676}




# 实验报告

## 简介
拼写检查（拼写纠错）任务是一项悠久的自然语言处理任务，旨在检测文本中的拼写错误并提供正确的拼写建议。拼写检查系统通常由两个主要组件组成：错误检测器和纠错器。当然如今也有些工作是将两个任务合并在一起，使用深度学习完成端到端的拼写纠错任务。

在机器学习之前就有通过规则的方式来进行拼写检查，例如使用词典。但是这种方法有一个缺点，就是无法处理未知词，以及当错误的词与另外一个正确的词相似时，可能会出现错误的纠正。尤其对于中文来说，使用拼写输入法导致拼写错误常表现为同音字、同形字、形近字等，这些错误很难通过规则来纠正。

之后随着机器学习算法的发展，几乎每一个当时火热的机器学习算法都被应用到了拼写检查任务中，例如贝叶斯方法、最大熵模型、条件随机场、神经网络等。其中神经网络在近年来取得了很大的进展，例如使用循环神经网络（RNN）、长短时记忆网络（LSTM）、卷积神经网络（CNN）等。这些方法通常会使用大量的数据进行训练，以提高模型的泛化能力。

下一个世代是以transformer为代表的预训练模型，这种模型在拼写检查任务中也取得了很好的效果。这种模型通常会使用大量的数据进行预训练，然后在特定任务上进行微调。这种方法的优点是可以很好的处理未知词，以及可以通过大量的数据进行训练，提高模型的泛化能力。如BERT、GPT、RoBERTa等。

这里为了开发的便捷性，我们在Hugging Face中寻找蒙古语的预训练模型，以此为基础开发拼写检查系统。

## 前期准备工作
这里对Huagging Face中的蒙古语预训练模型和多语言预训练模型进行了筛选，选择了一些适合拼写检查任务的模型。这些模型包括：
来自Baljinnyam[^1]的roberta
来自Blgn94[^2]的bert,roberta
来自bayartsogt[^3]的roberta,albert,bert
来自Dakie的[^4]的roberta,bert
来自tugstugi[^5]的bert
这些模型都是在蒙古语数据上进行了预训练的，在之后的各项任务中测试了这些模型的性能，最后选择了tugstugi的bert模型作为拼写检查系统的基础模型。


为了补充语料库，我们还使用了来自tugstugi整理的蒙古语新闻数据400M[^5]。


## 错误检测器
这里将任务分为两个部分，第一个部分是错误检测器，第二个部分是纠错器。
这里错误检测器一个简单的实现是使用分词器，将文本分词，对于拼写语言来说，分词器通常会将错误的词分成多个词，之后也可以通过词典来进一步检查.但是发现这会产生大量的假正例,几乎占据输出的一半,虽然之后的纠错器可以可以处理假正例,但是现任这会放大纠错器的错误率,显然当对于对于产生的Tf,会最后产生Tf*Cerrorrate个错误,所以这里我们选择了使用预训练模型来进行错误检测。
这里我们使用了tugstugi的bert模型，使用了400M的蒙古语新闻数据进行了微调，微调任务是token级的二分类任务，即对于每一个token，判断其是否是错误的token。这里使用了400M的数据进行了微调，错误样本有程序自动生成，产生两次内的拼写错误,包括删除、替换、插入、交换操作。对错误词后来所有位置标记,而非只标记错误token,这样可以更好的训练模型。要求模型寻找错误token位置是艰难地,因为很难区分一个词语中错误的位置,所以这里使用了一个简单的方法,即对于错误词的所有位置标记为错误,同时由此在最后预测时,提出两种策略,一种是单词中任意一个位置错误,即认为整个词是错误的,另一种是所有位置错误,即认为整个词是错误的。
这里在测试集上取得了很好的效果，F1值达到了0.9以上。并且由于这里假例子的数量较少，所以当纠错结果和原文相同,纠错器的设置了两个策略,则认为这里不存在错误跳过这里,另一种是认为这里存在错误,对于纠错器输出的多个结果,选择下一个.




## 纠错器
这里是tugstugi的bert模型，由于其使用MASK任务训练，所以可以很好的处理纠错任务。这里使用了错误检测器的输出，MASK掉错误的token，然后使用bert模型预测这些token。但是这里产生两个问题,一个是准确率问题,和token还原问题.
这里采用使用波束搜索为生成多个路径并预测缺失标签。与贪婪搜索不同，贪婪搜索在每一步选择概率最高的候选者，波束搜索维护一组最有前途的候选序列，称为波束。具体来说，算法如下进行： 

1.模型为错误位置𝑖生成一组词包括原文,MASK标记,和从词典中根据编辑距离搜索的相似词,对所以词替换错误位置进入Bert

2.每次选择概率最高的前𝑘个候选者，其中𝑘是波束宽度。 

3.将选定的候选者附加到前面的部分序列（从位置1到𝑖−1的预测标签）上，并计算扩展序列的联合概率。 


这里借由"扰乱"错误位置多次预测,希望得到这个位置更平均的预测结果,经过实验这一策略显然能提高性能


波束搜索算法旨在最大化整个序列的概率。执行波束搜索后，我们将所有解码路径合并在一个扁平列表中，并按照它们的各自概率对标签进行排序以产生最终排名。具体来说，对于错误位置i，让P(𝑙𝑗|𝑙1, . . . 𝑙𝑗−1)表示在路径𝑙1, . . . 𝑙𝑗−1给定的情况下观察到标签𝑙𝑗的预测概率。我们计算标签𝑙𝑗的路径独立边际概率为 P(𝑙𝑗) = max 可能路径𝑙1,...,𝑙𝑗−1 Ö 𝑗 𝑖=1 P(𝑙𝑖 |𝑙1, . . . 𝑙𝑖−1) ! 换句话说，我们取标签在分类法中所有可能路径上出现的最大概率。 

## 实验
无微调               {"wer": 0.16886705557261283, "cer": 0.03698977672512121}

500 微调 无多优化    {"wer": 0.1677472954180137, "cer": 0.036634655607753676}
{"wer": 0.16214849464501796, "cer": 0.035668605788474216}




在拼写纠错任务中，WER（Word Error Rate）和CER（Character Error Rate）是两个常用的性能指标，用于评估模型的纠错效果。

WER（Word Error Rate）：

定义：WER 是衡量系统输出与参考文本之间差异的指标，计算公式为：

WER = (S + D + I) / N
其中，S 是替换错误（substitutions），D 是删除错误（deletions），I 是插入错误（insertions），N 是参考文本中的单词总数。
用途：WER 主要用于评估语音识别系统和文本纠错系统的性能，反映了系统在单词层面上的错误率。
CER（Character Error Rate）：

定义：CER 是衡量系统输出与参考文本之间差异的指标，计算公式为：

CER = (S + D + I) / N
其中，S 是替换错误（substitutions），D 是删除错误（deletions），I 是插入错误（insertions），N 是参考文本中的字符总数。
用途：CER 主要用于评估文本纠错系统的性能，反映了系统在字符层面上的错误率。
这两个指标都用于量化模型的纠错能力，但侧重点不同：WER 关注单词层面的错误，而 CER 关注字符层面的错误。选择使用哪一个指标取决于具体应用场景和需求。


https://spellcheck.gov.mn/



https://github.com/shibing624/pycorrector/tree/master/examples/macbert





当然，下面是对上述方法的详细补充，结合数学公式来解释算法的工作原理。

### 1. 扰乱和替换错误位置
首先，为了增加模型的泛化能力，对于检测到的错误位置，不仅使用MASK标记，还将错误位置替换为词典中的相似词。设句子为 $S = \{w_1, w_2, \ldots, w_n\}$，错误位置为 $i$，我们可以表示为：

$$S' = \{w_1, \ldots, \text{MASK}, \ldots, w_n\} \quad \text{或} \quad S'' = \{w_1, \ldots, w_i', \ldots, w_n\}$$

其中，$w_i'$ 是词典中与 $w_i$ 相似的词。

### 2. 波束搜索算法
波束搜索算法是一种贪心算法，旨在最大化整个序列的概率。对于每一个错误位置，使用波束搜索算法生成多个路径并预测缺失标签。设波束宽度为 $B$，每一步选择概率最高的 $B$ 个路径继续扩展。具体来说，目标是最大化序列的条件概率：

$$P(S|S') = \prod_{i=1}^{n} P(w_i|w_{1:i-1})$$

波束搜索过程可以表示为：
1. 初始化：$K_0 = \{\text{[CLS]}\}$，$P(K_0) = 1$
2. 对于每一步 $t$，生成候选路径 $K_t$：
   $$K_t = \text{argmax}_k \sum_{j=1}^{B} P(K_{t-1}^j \cup \{w_t^k\}|S')$$
3. 选择 $B$ 个概率最高的路径继续扩展。

### 3. 路径合并与标签排序
执行波束搜索后，将所有解码路径合并在一个扁平列表中，并按照它们的各自概率对标签进行排序以产生最终排名。

设所有路径为 $\{K_1, K_2, \ldots, K_m\}$，每条路径的概率为 $P(K_i|S')$。对于标签 $l$，我们取标签在所有可能路径上出现的最大概率：

$$P(l|S') = \max_{i: l \in K_i} P(K_i|S')$$

### 4. 整体方法提高纠错性能
这种方法通过结合多个可能的路径和候选者，提高了纠错器的性能和准确率，能够更有效地处理拼写错误并生成正确的文本。

总结来说，整个算法通过以下步骤来实现：
1. **扰乱和替换错误位置**：使用MASK和相似词替换。
2. **波束搜索生成候选路径**：最大化序列的条件概率，选择最佳路径。
3. **合并路径并排序标签**：对标签进行概率排序，取最大概率标签。

通过上述过程，模型能够更好地处理文本中的拼写错误，提高生成文本的准确性。


### 两个模型的错误叠加问题
对于拼写检测器的真正例、真负例、假正例、假负例，分别设为
TP^d 将错误的单词标记为错误
TN^d 将正确的单词标记为正确
FP^d 将正确的单词标记为错误
FN^d 将错误的单词标记为正确

对于纠错器的真正例、真负例、假正例、假负例，分别设为
TP^c 将错误的单词纠正为正确
TN^c 将正确的单词保持正确
FP^c 将正确的单词纠正为错误
FN^c 将错误的单词保持错误

再设产生TP^d的概率为PTP^d = TP^d/(P^d+N^d) ...
那么对于整个拼写检查系统，我们可以定义如下指标：

P^c = PTP^d * (P^d+N^d)
N^c = PFP^d * (P^d+N^d)
P^c+N^c = (PTP^d + PFP^d) * (P^d+N^d)

总错误数 = PFN^d * (P^d+N^d) + PFP^c * (P^c+N^c) + PFN^c * (P^c+N^c) - PTN^c * (P^c+N^c)
= PFN^d * (P^d+N^d) + (PFP^c + PFN^c - PTN^c) * (P^c+N^c)
= PFN^d * (P^d+N^d) + (PFP^c + PFN^c - PTN^c) * (PTP^d + PFP^d) * (P^d+N^d)
= PFN^d * (P^d+N^d) + (PFP^c + PFN^c - PTN^c) * (PTP^d + PFP^d) * (P^d+N^d)

去掉其中常数项，我们可以得到粗略的表示错误率的公式：

= NPF^d + (PFP^c + PFN^c - PTN^c) * (PTP^d + PFP^d)

根据其中可知，若设一个模型的PFN 和 PFP 的概率不可同时降低，那么我们可以选择两种策略。
一种是降低PFN^d，即提高检测器的查全率，同时降低PFP^c,即提高纠错器的查准率,这个策略可以解释为，我们可以通过提高检测器的查全率，减少错误的纠正，同时提高纠错器的查准率，减少错误的纠正，从而降低整个系统的错误率。
另一种策略是降低PFP^d，即提高检测器的查准率，同时降低PFN^c,即提高纠错器的查全率,这个策略可以解释为，我们可以通过提高检测器的查准率，减少错误的标记，同时提高纠错器的查全率，减少错误的纠正，从而降低整个系统的错误率。

